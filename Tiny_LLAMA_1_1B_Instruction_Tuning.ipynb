{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "efc47d64bc1941fc81b5c97c978461cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_917a8803da744b47b4d1138553e9ccfd",
              "IPY_MODEL_67e38ed487e74ac78a4bab05394ef52a",
              "IPY_MODEL_75fa19369285494294c8a7237a1991b4"
            ],
            "layout": "IPY_MODEL_67c325b197d44cffb1f95cdd240d61f0"
          }
        },
        "917a8803da744b47b4d1138553e9ccfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa70bbd9cb4b45f4b0d6e60ac2690dea",
            "placeholder": "​",
            "style": "IPY_MODEL_4813d801b5d742d7b463c27c43a16572",
            "value": "Map: 100%"
          }
        },
        "67e38ed487e74ac78a4bab05394ef52a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dadb54a82c2641e0a37f14d3f138d8aa",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_718cc0c6c61b445b80e5c5423213cd01",
            "value": 10000
          }
        },
        "75fa19369285494294c8a7237a1991b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_889d0b023e0e46b88c1a993cec70f698",
            "placeholder": "​",
            "style": "IPY_MODEL_96b6059cff0d4691b32491878a9e0b3f",
            "value": " 10000/10000 [01:13&lt;00:00, 223.36 examples/s]"
          }
        },
        "67c325b197d44cffb1f95cdd240d61f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa70bbd9cb4b45f4b0d6e60ac2690dea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4813d801b5d742d7b463c27c43a16572": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dadb54a82c2641e0a37f14d3f138d8aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "718cc0c6c61b445b80e5c5423213cd01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "889d0b023e0e46b88c1a993cec70f698": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96b6059cff0d4691b32491878a9e0b3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "538312d0086848bf955cb5bff4de7dc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1dca412336364c778214e4e5013ec1bf",
              "IPY_MODEL_351e9b06884b492b9467bb5fa024f0e5",
              "IPY_MODEL_8f2d282caacf4db3ba05b15d1f71b0c6"
            ],
            "layout": "IPY_MODEL_6a4a39663b64448d941bd6400ba963ce"
          }
        },
        "1dca412336364c778214e4e5013ec1bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4b4d0f8b0534d74ae996e35bc3b6f0e",
            "placeholder": "​",
            "style": "IPY_MODEL_9516ecd5eb7e47d5bd1febfb0632b382",
            "value": "Map: 100%"
          }
        },
        "351e9b06884b492b9467bb5fa024f0e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21169ad9164746b4880d3f7694f76589",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d31247322a840d18b1375c456a617ba",
            "value": 10000
          }
        },
        "8f2d282caacf4db3ba05b15d1f71b0c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22b48bab7c284262a3afceb8cc26acb2",
            "placeholder": "​",
            "style": "IPY_MODEL_f47347859d7d45a1b66a80ee48547aa5",
            "value": " 10000/10000 [00:57&lt;00:00, 160.28 examples/s]"
          }
        },
        "6a4a39663b64448d941bd6400ba963ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4b4d0f8b0534d74ae996e35bc3b6f0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9516ecd5eb7e47d5bd1febfb0632b382": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21169ad9164746b4880d3f7694f76589": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d31247322a840d18b1375c456a617ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "22b48bab7c284262a3afceb8cc26acb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f47347859d7d45a1b66a80ee48547aa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2m4CHi9km1Z",
        "outputId": "34185a19-207c-46a3-ceb6-1db43b0f03a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.4/318.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.9/105.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.5/322.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m735.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -q accelerate -U\n",
        "!pip install -q bitsandbytes -U\n",
        "!pip install -q trl -U\n",
        "!pip install -q peft -U\n",
        "!pip install -q transformers -U\n",
        "!pip install datasets -U"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"HuggingFaceH4/ultrachat_200k\", trust_remote_code=True, split='train_sft')"
      ],
      "metadata": {
        "id": "XeOIsBBrlKt-"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CR-68lyYGyKX",
        "outputId": "8165314c-f1fa-4318-f29f-96ab7502a636"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['prompt', 'prompt_id', 'messages'],\n",
              "    num_rows: 207865\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.shuffle(seed=0).select(range(10_000))"
      ],
      "metadata": {
        "id": "B3-y6jcsGe8_"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "template_tokenizer = AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n",
        "\n",
        "def format_prompt(example):\n",
        "    ''' Format the prompt using the <|user|> and <|assistant|> format'''\n",
        "    chat = example['messages']\n",
        "    prompt = template_tokenizer.apply_chat_template(chat, tokenizer=False)\n",
        "\n",
        "    return {'text':str(prompt)}"
      ],
      "metadata": {
        "id": "BlP74fLk7ScO"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(format_prompt(dataset[0]).keys())\n",
        "print(format_prompt(dataset[0])['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgdZXEJKC0lm",
        "outputId": "0a35b005-6dbf-4df2-facc-c5e5c32fa506"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['text'])\n",
            "[529, 29989, 1792, 29989, 29958, 13, 29941, 29889, 940, 271, 278, 18655, 1849, 297, 1045, 6504, 4094, 363, 278, 13622, 931, 29889, 2, 29871, 13, 29966, 29989, 465, 22137, 29989, 29958, 13, 29902, 437, 451, 505, 2472, 1048, 278, 2702, 1134, 310, 18655, 1849, 1641, 12992, 304, 29889, 2398, 29892, 1244, 526, 2498, 11994, 363, 1045, 6504, 1556, 18655, 1849, 29901, 13, 13, 29896, 29889, 399, 1161, 278, 18655, 1849, 26606, 411, 5941, 4094, 29889, 13, 29906, 29889, 315, 329, 278, 18655, 1849, 964, 2319, 470, 18350, 29899, 29879, 1891, 12785, 29889, 13, 29941, 29889, 1771, 292, 263, 3104, 310, 4094, 304, 1045, 309, 373, 278, 380, 994, 29889, 13, 29946, 29889, 3462, 263, 12534, 305, 310, 15795, 304, 278, 1045, 6504, 4094, 29889, 13, 29945, 29889, 3462, 278, 18655, 1849, 304, 278, 1045, 6504, 4094, 29889, 13, 29953, 29889, 17278, 278, 18655, 1849, 363, 278, 13622, 931, 313, 4149, 7984, 292, 11994, 373, 278, 3577, 470, 1106, 701, 7984, 292, 3064, 363, 2702, 18655, 1849, 7395, 467, 13, 29955, 29889, 4321, 278, 18655, 1849, 363, 1016, 18543, 773, 263, 27350, 470, 263, 889, 1607, 29889, 2688, 881, 367, 22707, 541, 451, 975, 1111, 12504, 322, 286, 1878, 29891, 29889, 13, 29947, 29889, 9038, 278, 18655, 1849, 526, 7984, 287, 304, 596, 7429, 10331, 824, 404, 29892, 3349, 963, 515, 278, 1045, 6504, 4094, 773, 263, 2243, 15048, 805, 6150, 470, 263, 5312, 4983, 29889, 13, 29929, 29889, 360, 6038, 278, 18655, 1849, 322, 9080, 7375, 411, 596, 25448, 4259, 886, 470, 12507, 346, 29889, 2, 29871, 13, 29966, 29989, 1792, 29989, 29958, 13, 6028, 366, 788, 777, 2472, 373, 920, 304, 5557, 278, 18655, 1849, 515, 2805, 2086, 4964, 470, 975, 1111, 12504, 29973, 2, 29871, 13, 29966, 29989, 465, 22137, 29989, 29958, 13, 29907, 13946, 368, 29892, 1244, 526, 777, 25562, 304, 5557, 18655, 1849, 515, 2805, 2086, 4964, 470, 975, 1111, 12504, 29901, 13, 13, 29896, 29889, 4803, 10849, 18655, 1849, 29901, 383, 3781, 18655, 1849, 1996, 3109, 7984, 292, 931, 322, 11551, 1009, 18459, 322, 21054, 272, 2253, 1135, 9642, 18655, 1849, 29889, 29871, 29906, 29889, 315, 329, 18655, 1849, 964, 9090, 29899, 29879, 1891, 12785, 29901, 315, 329, 1259, 278, 18655, 1849, 964, 697, 29899, 22466, 470, 9090, 29899, 29879, 1891, 12785, 6911, 304, 9801, 1584, 7984, 292, 29889, 29871, 29941, 29889, 4803, 263, 12237, 29901, 3789, 263, 12237, 5034, 304, 278, 13622, 7984, 292, 931, 363, 278, 18655, 519, 366, 29915, 276, 7984, 292, 29889, 6811, 15108, 292, 508, 4556, 18655, 1849, 304, 4953, 286, 1878, 29891, 29889, 29871, 29946, 29889, 323, 4350, 1243, 29901, 4321, 278, 18655, 1849, 263, 2846, 6233, 1434, 278, 13622, 7984, 292, 931, 338, 975, 29889, 960, 278, 18655, 519, 338, 22707, 322, 7984, 287, 29892, 3349, 372, 515, 278, 12871, 29889, 29871, 29945, 29889, 4803, 11220, 4094, 304, 5040, 7984, 292, 29901, 2860, 7984, 292, 29892, 270, 6038, 278, 18655, 519, 7389, 322, 1065, 372, 1090, 11220, 4094, 304, 5040, 278, 7984, 292, 1889, 29889, 29871, 29953, 29889, 319, 5405, 975, 29883, 798, 8497, 278, 3104, 29901, 6811, 29883, 798, 8497, 508, 1207, 278, 18655, 1849, 7984, 1597, 854, 368, 322, 2125, 5520, 304, 7984, 29889, 29871, 29955, 29889, 4803, 1886, 11500, 470, 1999, 14588, 292, 1158, 29901, 3967, 1886, 11500, 470, 1999, 14588, 292, 2012, 310, 1045, 6504, 304, 19905, 278, 18459, 310, 278, 18655, 1849, 29889, 2973, 1438, 25562, 29892, 366, 881, 367, 2221, 304, 7984, 18655, 1849, 393, 526, 9226, 29892, 22707, 322, 2989, 310, 21054, 272, 29889, 2, 29871, 13, 29966, 29989, 1792, 29989, 29958, 13, 23323, 366, 884, 2367, 592, 777, 10529, 373, 825, 4072, 310, 4259, 292, 470, 12507, 346, 306, 1033, 671, 304, 1207, 590, 12461, 29887, 583, 21779, 2253, 29973, 2, 29871, 13, 29966, 29989, 465, 22137, 29989, 29958, 13, 29907, 13946, 368, 29991, 1932, 372, 5304, 304, 4259, 292, 470, 12507, 3277, 18655, 1849, 29892, 727, 526, 1095, 2222, 24496, 29889, 2266, 526, 777, 7014, 304, 1207, 596, 18655, 1849, 21779, 2253, 29901, 13, 13, 29896, 29889, 438, 9258, 438, 309, 322, 8836, 265, 5342, 625, 29901, 319, 22037, 10545, 4259, 292, 29892, 1671, 777, 288, 9258, 17182, 322, 263, 8536, 1161, 310, 454, 3712, 3623, 625, 975, 596, 12461, 29887, 583, 363, 263, 503, 14596, 29892, 18806, 29891, 21054, 272, 29889, 29871, 29906, 29889, 1105, 29891, 23863, 346, 322, 402, 5621, 29901, 23478, 577, 29891, 12507, 346, 322, 867, 630, 330, 5621, 363, 385, 20021, 20603, 4259, 292, 393, 29915, 645, 2367, 596, 18655, 1849, 263, 4497, 1017, 24817, 29889, 29871, 29941, 29889, 7455, 506, 322, 2439, 5824, 29901, 23478, 1375, 1133, 7171, 506, 322, 10849, 902, 5824, 29892, 763, 610, 29879, 2330, 29892, 696, 12846, 653, 470, 266, 25395, 29892, 411, 288, 9258, 17182, 322, 15795, 363, 263, 25620, 10800, 273, 4259, 292, 29889, 29871, 29946, 29889, 350, 1338, 314, 293, 12540, 387, 279, 29901, 360, 374, 5617, 280, 289, 1338, 314, 293, 13848, 387, 279, 975, 596, 7984, 287, 18655, 1849, 363, 263, 8261, 29892, 8437, 29891, 21054, 272, 29889, 29871, 29945, 29889, 1459, 4467, 273, 6561, 968, 29901, 1383, 1351, 777, 610, 4467, 273, 923, 968, 975, 596, 12461, 29887, 583, 363, 263, 18254, 1017, 29892, 4497, 1017, 6124, 29889, 29871, 29953, 29889, 349, 4778, 29901, 23478, 2362, 309, 282, 4778, 411, 777, 288, 9258, 17182, 322, 788, 304, 596, 18655, 1849, 363, 263, 21054, 272, 1319, 29892, 18806, 29891, 24817, 29889, 29871, 29955, 29889, 323, 801, 2172, 23863, 346, 29901, 23478, 260, 801, 2172, 29892, 454, 3712, 3623, 625, 322, 7171, 506, 297, 263, 12580, 29880, 29892, 788, 777, 4094, 363, 263, 907, 25934, 260, 801, 2172, 12507, 346, 393, 1614, 1860, 738, 12461, 29887, 583, 29889, 4525, 526, 925, 263, 2846, 4259, 292, 7014, 29889, 3617, 907, 1230, 322, 1018, 596, 1914, 805, 625, 18240, 29889, 18804, 4259, 292, 470, 12507, 346, 508, 1207, 596, 18655, 1849, 21779, 628, 14803, 322, 5566, 11407, 29991, 2, 29871, 13, 29966, 29989, 1792, 29989, 29958, 13, 1349, 968, 4259, 292, 7014, 526, 21863, 292, 29991, 1815, 366, 2367, 592, 777, 901, 7014, 373, 920, 304, 7984, 12461, 29887, 583, 297, 263, 9045, 29891, 322, 21054, 272, 1319, 982, 29973, 2, 29871, 13, 29966, 29989, 465, 22137, 29989, 29958, 13, 2776, 3236, 29892, 1244, 526, 263, 2846, 901, 7014, 373, 920, 304, 7984, 596, 12461, 29887, 583, 297, 263, 9045, 29891, 322, 21054, 272, 1319, 982, 29901, 13, 13, 29896, 29889, 1528, 579, 292, 29901, 1528, 579, 292, 596, 18655, 1849, 338, 385, 4780, 322, 9045, 29891, 982, 304, 6963, 714, 1009, 5613, 21054, 943, 29889, 4721, 354, 271, 596, 288, 854, 304, 29871, 29946, 29900, 29900, 29943, 29892, 28189, 596, 12461, 29887, 583, 411, 263, 2217, 2586, 310, 288, 9258, 17182, 29892, 15795, 322, 1236, 2496, 29892, 322, 696, 579, 963, 363, 29871, 29906, 29900, 29899, 29941, 29900, 6233, 29889, 13, 13, 29906, 29889, 1632, 8873, 29901, 1632, 8873, 338, 263, 2107, 982, 304, 7984, 18655, 1849, 2645, 11801, 29889, 315, 329, 596, 12461, 29887, 583, 964, 2919, 12785, 29892, 1506, 1878, 963, 411, 288, 9258, 17182, 29892, 4259, 411, 15795, 322, 1236, 2496, 29892, 322, 867, 453, 963, 363, 263, 2846, 6233, 373, 1269, 2625, 29889, 13, 13, 29941, 29889, 624, 381, 29899, 29888, 719, 292, 29901, 624, 381, 29899, 29888, 719, 292, 338, 263, 4996, 322, 9045, 29891, 982, 304, 7984, 18655, 1849, 29889, 940, 271, 777, 17182, 297, 263, 281, 554, 470, 263, 7243, 29892, 788, 596, 3060, 2986, 12461, 29887, 583, 29892, 322, 23546, 29899, 29888, 719, 963, 363, 263, 2846, 6233, 2745, 896, 29915, 276, 22707, 3447, 2181, 11936, 29889, 3462, 777, 577, 29891, 12507, 346, 29892, 330, 5621, 470, 7171, 506, 363, 4805, 21054, 272, 29889, 13, 13, 29946, 29889, 2443, 11500, 29901, 2443, 11500, 338, 263, 9045, 29891, 7984, 292, 1158, 393, 2225, 20098, 278, 4866, 18254, 29878, 654, 322, 18459, 29889, 15484, 596, 12461, 29887, 583, 297, 263, 1886, 4183, 25972, 29892, 322, 21837, 963, 363, 29871, 29945, 29899, 29955, 6233, 29892, 4259, 963, 411, 902, 5824, 29892, 541, 357, 470, 454, 3712, 3623, 625, 29889, 13, 13, 29945, 29889, 317, 18560, 292, 29901, 317, 18560, 287, 18655, 1849, 508, 367, 263, 5192, 29891, 2625, 270, 728, 470, 6766, 408, 278, 1667, 3236, 29889, 940, 271, 777, 541, 357, 470, 288, 9258, 17182, 297, 263, 7243, 29892, 788, 596, 3060, 2986, 12461, 29887, 583, 322, 872, 329, 29948, 963, 363, 263, 2846, 6233, 2745, 896, 29915, 276, 22707, 3447, 2181, 11936, 29889, 3462, 777, 902, 5824, 29892, 15795, 470, 805, 1575, 363, 4805, 21054, 272, 29889, 13, 13, 1349, 968, 526, 925, 263, 2846, 7984, 292, 7014, 29889, 2169, 538, 2222, 310, 920, 366, 7984, 596, 12461, 29887, 583, 29892, 6456, 304, 671, 10849, 7738, 29892, 7639, 1422, 805, 1575, 322, 13389, 1009, 5613, 21054, 943, 29991, 2, 29871, 13]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.map(format_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "efc47d64bc1941fc81b5c97c978461cc",
            "917a8803da744b47b4d1138553e9ccfd",
            "67e38ed487e74ac78a4bab05394ef52a",
            "75fa19369285494294c8a7237a1991b4",
            "67c325b197d44cffb1f95cdd240d61f0",
            "aa70bbd9cb4b45f4b0d6e60ac2690dea",
            "4813d801b5d742d7b463c27c43a16572",
            "dadb54a82c2641e0a37f14d3f138d8aa",
            "718cc0c6c61b445b80e5c5423213cd01",
            "889d0b023e0e46b88c1a993cec70f698",
            "96b6059cff0d4691b32491878a9e0b3f"
          ]
        },
        "id": "GYBPYvi3C-iO",
        "outputId": "ccc6ed7c-4889-4c9c-da77-c1c72f5f0603"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "efc47d64bc1941fc81b5c97c978461cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2724 > 2048). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing Base LLAMA Model\n",
        "\n",
        "\n",
        "*   Let's see how base Tiny-LLAMA performs out of the box\n",
        "\n"
      ],
      "metadata": {
        "id": "of-RHll4Dx7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# base model\n",
        "model_name ='TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T'\n",
        "\n",
        "pipe = pipeline(task='text-generation', model=model_name, device='cuda')\n",
        "\n",
        "# prompt\n",
        "# <|user>, <|assistant|>\n",
        "\n",
        "prompt = '''<|user|>\n",
        "Tell me something about LLM's.\n",
        "<|assistant|>\n",
        "'''\n",
        "\n",
        "prompt = '''\n",
        "Tell me something about LLM's.\n",
        "'''\n",
        "\n",
        "output = pipe(prompt)\n",
        "output"
      ],
      "metadata": {
        "id": "Of-LFJ0EDt6-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cea0b6bb-a7f9-423f-c812-90e70e9a39e0"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': '\\nTell me something about LLM\\'s.\\n\\nA: I think you are looking for the word \"tell\" in the context of \"something about LLM\\'s\".\\n\\nA: I think you are looking for the word \"tell\" in the context of \"something about LLM\\'s\".\\n'}]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model configuration for training"
      ],
      "metadata": {
        "id": "6s_BrFsqRVhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig"
      ],
      "metadata": {
        "id": "lThgxh3tO-5S"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# do the 4-bit quantization configuration in Q-LoRA\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type='nf4',\n",
        "    bnb_4bit_comput_dtype='float16',\n",
        "    bnb_4bit_use_double_quant=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZIUDUZdRmaN",
        "outputId": "bc5a0942-5912-4d8e-ab7c-0fd6ac3ff3fb"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unused kwargs: ['bnb_4bit_comput_dtype']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer.pad_token='<PAD>'\n",
        "tokenizer.padding_size='left'"
      ],
      "metadata": {
        "id": "Cd0XCm6iSMNE"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map = 'auto',\n",
        "    quantization_config=bnb_config\n",
        ")"
      ],
      "metadata": {
        "id": "Rx8p2BijS-QK"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.use_cache=False\n",
        "model.config.pretraining_tp =1"
      ],
      "metadata": {
        "id": "FEqxnQwLTQQv"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlRYYKYKUTze",
        "outputId": "cd2ab079-e6e0-4b42-c210-f97466926ce3"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LlamaForCausalLM(\n",
              "  (model): LlamaModel(\n",
              "    (embed_tokens): Embedding(32000, 2048)\n",
              "    (layers): ModuleList(\n",
              "      (0-21): 22 x LlamaDecoderLayer(\n",
              "        (self_attn): LlamaSdpaAttention(\n",
              "          (q_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
              "          (k_proj): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
              "          (v_proj): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
              "          (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
              "          (rotary_emb): LlamaRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): LlamaMLP(\n",
              "          (gate_proj): Linear4bit(in_features=2048, out_features=5632, bias=False)\n",
              "          (up_proj): Linear4bit(in_features=2048, out_features=5632, bias=False)\n",
              "          (down_proj): Linear4bit(in_features=5632, out_features=2048, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
              "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
              "      )\n",
              "    )\n",
              "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=2048, out_features=32000, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare LoRA Configuration for PEFT Fine tuning"
      ],
      "metadata": {
        "id": "5lwIsTrkTzqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.1,\n",
        "    r=64,\n",
        "    bias='none',\n",
        "    task_type='CAUSAL_LM',\n",
        "    target_modules=['q_proj','k_proj','v_proj','o_proj','gate_proj','up_proj','down_proj']\n",
        ")\n",
        "\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "\n",
        "model = get_peft_model(model, peft_config)"
      ],
      "metadata": {
        "id": "ZkHbWP_FTiMU"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = 2048*256\n",
        "a = 2048*64\n",
        "b = 64*256\n",
        "\n",
        "w, a, b, a+b, (a+b)/w"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wy6KmGRDVaZ8",
        "outputId": "9865ba2e-0222-4be1-998e-548d18fc91c7"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(524288, 131072, 16384, 147456, 0.28125)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LixL141Ssht3",
        "outputId": "6a90899f-6a12-4b5d-8aa9-eb9f74bdebf2"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): LlamaForCausalLM(\n",
              "      (model): LlamaModel(\n",
              "        (embed_tokens): Embedding(32000, 2048)\n",
              "        (layers): ModuleList(\n",
              "          (0-21): 22 x LlamaDecoderLayer(\n",
              "            (self_attn): LlamaSdpaAttention(\n",
              "              (q_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=64, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=64, out_features=2048, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=64, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=64, out_features=256, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (v_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=64, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=64, out_features=256, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (o_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=64, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=64, out_features=2048, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (rotary_emb): LlamaRotaryEmbedding()\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2048, out_features=5632, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=64, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=64, out_features=5632, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (up_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2048, out_features=5632, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=64, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=64, out_features=5632, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (down_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=5632, out_features=2048, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=5632, out_features=64, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=64, out_features=2048, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
              "            (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "        (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
              "        (rotary_emb): LlamaRotaryEmbedding()\n",
              "      )\n",
              "      (lm_head): Linear(in_features=2048, out_features=32000, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8HAlL1QBBiV",
        "outputId": "64ba766f-08f6-40b4-e1c9-04c02ebfdc32"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['prompt', 'prompt_id', 'messages', 'text'],\n",
              "    num_rows: 10000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Fine Tuning"
      ],
      "metadata": {
        "id": "O7jgvuqknovi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "from trl import SFTTrainer\n",
        "\n",
        "output_dir = 'train_dir'\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=4,\n",
        "    optim='paged_adamw_32bit',\n",
        "    learning_rate=2e-4,\n",
        "    lr_scheduler_type='cosine',\n",
        "    num_train_epochs=1,\n",
        "    logging_steps=10,\n",
        "    fp16=True,\n",
        "    gradient_checkpointing=True\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(model=model,\n",
        "    train_dataset=dataset,\n",
        "    dataset_text_field='text',\n",
        "    tokenizer=tokenizer,\n",
        "    args=args,\n",
        "    max_seq_length=512,\n",
        "    peft_config=peft_config\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "538312d0086848bf955cb5bff4de7dc1",
            "1dca412336364c778214e4e5013ec1bf",
            "351e9b06884b492b9467bb5fa024f0e5",
            "8f2d282caacf4db3ba05b15d1f71b0c6",
            "6a4a39663b64448d941bd6400ba963ce",
            "e4b4d0f8b0534d74ae996e35bc3b6f0e",
            "9516ecd5eb7e47d5bd1febfb0632b382",
            "21169ad9164746b4880d3f7694f76589",
            "9d31247322a840d18b1375c456a617ba",
            "22b48bab7c284262a3afceb8cc26acb2",
            "f47347859d7d45a1b66a80ee48547aa5"
          ]
        },
        "id": "S6rZBLxZnhwT",
        "outputId": "9606ea10-3a8e-47b0-cc00-af78eb21b100"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '1.0.0'.\n",
            "\n",
            "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:283: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:321: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "538312d0086848bf955cb5bff4de7dc1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/nn/modules.py:452: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='845' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 845/1250 54:27 < 26:09, 0.26 it/s, Epoch 0.68/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.350600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.187300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.150500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.131400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.098500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.067000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.067000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.047200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>1.066400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.036700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>1.007500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>1.009500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>1.008700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.980800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.978900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.968800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.986200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.978700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.956700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.951400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.958000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.979900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.911300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.928200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.920400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.925700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.912700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.906900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.924500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.876600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>0.892600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.894800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>0.900100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.910900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.892000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.917600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>0.887200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.898600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>0.895800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.894300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>0.881800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>0.885100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>0.857400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>0.865400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.887300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.876200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>0.856800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.852300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>0.862500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.838700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>0.857100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>0.863200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>530</td>\n",
              "      <td>0.860400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>0.833800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.827200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>0.846200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>570</td>\n",
              "      <td>0.849300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>0.852200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>590</td>\n",
              "      <td>0.867700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.867500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>610</td>\n",
              "      <td>0.853500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>0.829300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>630</td>\n",
              "      <td>0.831600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>0.825200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.827500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>0.821000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>670</td>\n",
              "      <td>0.820900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>0.820300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>690</td>\n",
              "      <td>0.825100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.786900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>710</td>\n",
              "      <td>0.823300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>0.795800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>730</td>\n",
              "      <td>0.812000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>0.804700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.830000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>0.790700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>770</td>\n",
              "      <td>0.786700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>0.812000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>790</td>\n",
              "      <td>0.811100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.812900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>810</td>\n",
              "      <td>0.788500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>820</td>\n",
              "      <td>0.791200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>830</td>\n",
              "      <td>0.790700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>0.783500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.model.save_pretrained(\"TinyLlama-1.1B-qlora\")"
      ],
      "metadata": {
        "id": "JDDDDXceq0ws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Pre-Trained PEFT Model for Prediction"
      ],
      "metadata": {
        "id": "2PdYEqgNGv36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import AutoPeftModelForCausalLM\n",
        "\n",
        "model = AutoPeftModelForCausalLM.from_pretrained(\n",
        "    \"TinyLlama-1.1B-qlora\",\n",
        "    device_map='auto'\n",
        ")\n",
        "\n",
        "merged_model = model.merge_and_unload()"
      ],
      "metadata": {
        "id": "N7tFJXGRGsDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "prompt='''<|User|>\n",
        "Tell me something about Large Language Models.</s>\n",
        "<|assistant|>\n",
        "'''\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer.pad_token = '<PAD>'\n",
        "tokenizer.padding_size='left'\n",
        "\n",
        "pipe = pipeline(task='text-generation', model=merged_model, tokenizer=tokenizer)\n",
        "output = pipe(prompt)\n",
        "print(output[0]['generated_text'])"
      ],
      "metadata": {
        "id": "V7gDPqWZHavR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## output:\n",
        "'''<|user|>\n",
        "Tell me something about Large Language Models.</s>\n",
        "<|assistant|>\n",
        "Large Language Models (LLMs) are a type of artificial intelligence (AI) that can generate human-like language. They are trained on large amounts of text data, such as Wikipedia articles, to create a model that can generate natural-sounding sentences.\n",
        "\n",
        "LLMs are becoming increasingly popular in various fields, including natural language processing (NLP), machine translation, and chatbots. They are used to generate text in a variety of languages, including English, French, German, and Spanish.\n",
        "\n",
        "One of the key advantages of LLMs is their ability to generate natural-sounding sentences that are similar to human language. This is achieved through the use of deep learning algorithms that learn to recognize patterns in text data and generate sentences that are similar to human language.\n",
        "\n",
        "Another advantage of LLMs is their ability to handle complex language tasks, such as machine translation, where human translators struggle to generate accurate translations. LLMs can generate natural-sounding sentences that are accurate and comprehensible, even when dealing with difficult language combinations.\n",
        "\n",
        "Overall, LLMs are a powerful tool that can help to improve the quality and efficiency of various NLP applications. They are becoming increasingly popular in a variety of fields, and their use is expected to continue to grow in the futur\n",
        "'''"
      ],
      "metadata": {
        "id": "WtneVJ-zIaw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r tiny_llama_qlora_adapter.zip TinyLlama-1.1B-qlora"
      ],
      "metadata": {
        "id": "u2p0KPGpVDGN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}